{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langfuse import Langfuse\n",
    "from langchain_community.document_loaders import PyPDFLoader  \n",
    "import os\n",
    "import re\n",
    "from pinecone import Pinecone\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import StateGraph\n",
    "from langfuse import Langfuse\n",
    "from langfuse.callback import CallbackHandler\n",
    "from langchain.schema import Document\n",
    "from datetime import datetime\n",
    "from datetime import datetime\n",
    "\n",
    "# from langfuse.client import CreateTracer, Creategeneration, CreateSpan\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "LANGFUSE_SECRET_KEY = os.getenv(\"LANGFUSE_SECRET_KEY\")\n",
    "LANGFUSE_PUBLIC_KEY = os.getenv(\"LANGFUSE_PUBLIC_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "langfuse = Langfuse(\n",
    "    secret_key=LANGFUSE_SECRET_KEY,\n",
    "    public_key=LANGFUSE_PUBLIC_KEY,\n",
    "    host=\"https://us.cloud.langfuse.com\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read PDF Files + RAG using Pinecone\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read PDF Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경로: C:\\Users\\yjw64\\projects\\github\\kairos\\KAIROS_Podcast\\example_files\\[Lecture] 12. IP in Linux.pdf\n",
      "존재 여부: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 복사한 절대 경로 붙여넣기\n",
    "path = r\"C:\\Users\\yjw64\\projects\\github\\kairos\\KAIROS_Podcast\\example_files\\[Lecture] 12. IP in Linux.pdf\"\n",
    "\n",
    "print(\"경로:\", path)\n",
    "print(\"존재 여부:\", os.path.exists(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 12 0 (offset 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 26 0 (offset 0)\n",
      "Ignoring wrong pointing object 28 0 (offset 0)\n",
      "Ignoring wrong pointing object 30 0 (offset 0)\n",
      "Ignoring wrong pointing object 32 0 (offset 0)\n",
      "Ignoring wrong pointing object 34 0 (offset 0)\n",
      "Ignoring wrong pointing object 36 0 (offset 0)\n",
      "Ignoring wrong pointing object 47 0 (offset 0)\n",
      "Ignoring wrong pointing object 53 0 (offset 0)\n",
      "Ignoring wrong pointing object 59 0 (offset 0)\n",
      "Ignoring wrong pointing object 68 0 (offset 0)\n",
      "Ignoring wrong pointing object 84 0 (offset 0)\n",
      "Ignoring wrong pointing object 87 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 95 0 (offset 0)\n",
      "Ignoring wrong pointing object 97 0 (offset 0)\n",
      "Ignoring wrong pointing object 103 0 (offset 0)\n",
      "Ignoring wrong pointing object 105 0 (offset 0)\n",
      "Ignoring wrong pointing object 134 0 (offset 0)\n",
      "Ignoring wrong pointing object 148 0 (offset 0)\n",
      "Ignoring wrong pointing object 154 0 (offset 0)\n",
      "Ignoring wrong pointing object 181 0 (offset 0)\n",
      "Ignoring wrong pointing object 183 0 (offset 0)\n",
      "Ignoring wrong pointing object 201 0 (offset 0)\n",
      "Ignoring wrong pointing object 203 0 (offset 0)\n",
      "Ignoring wrong pointing object 218 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "pdf_paths = [\n",
    "    r\"C:\\Users\\yjw64\\projects\\github\\kairos\\KAIROS_Podcast\\example_files\\[Lecture] 12. IP in Linux.pdf\"\n",
    "]\n",
    "\n",
    "documents = []\n",
    "\n",
    "for path in pdf_paths:\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"파일 없음: {path}\")\n",
    "        continue\n",
    "    # 1. 파일명에서 [세션명] 추출\n",
    "    file_name = os.path.basename(path)\n",
    "    match = re.search(r\"\\[(.*?)\\]\", file_name)\n",
    "    session = match.group(1) if match else \"Unknown Session\"\n",
    "\n",
    "    # 2. PDF 로딩\n",
    "    loader = PyPDFLoader(path)\n",
    "    docs = loader.load()\n",
    "    # date 정보 추가\n",
    "    date = datetime.today().strftime(\"%Y-%m-%d\") #ex)2025-01-01\n",
    "\n",
    "    # 3. 메타데이터 추가\n",
    "    for doc in docs:\n",
    "        doc.metadata[\"session\"] = session\n",
    "        doc.metadata[\"date\"] = date\n",
    "\n",
    "    documents.extend(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'macOS 버전 15.4.1(빌드 24E263) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250514085129Z00'00'\", 'moddate': \"D:20250514085129Z00'00'\", 'source': 'C:\\\\Users\\\\yjw64\\\\projects\\\\github\\\\kairos\\\\KAIROS_Podcast\\\\example_files\\\\[Lecture] 12. IP in Linux.pdf', 'total_pages': 34, 'page': 0, 'page_label': '1', 'session': 'Lecture', 'date': '2025-05-21'}, page_content='System Programming\\nLecture#12IP in Linux')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check documents\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAIEmbeddings 인스턴스 생성\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    model=\"text-embedding-3-small\"\n",
    ")\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index = pc.Index(\"kairos-podcast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'lecturedata': {'vector_count': 120},\n",
      "                'userqna': {'vector_count': 3}},\n",
      " 'total_vector_count': 123,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "#check connection\n",
    "print(index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#저장할 vector store 불러오기\n",
    "vector_store = PineconeVectorStore(\n",
    "    index=index, \n",
    "    embedding=embeddings,\n",
    "    namespace=\"lecturedata\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "split_docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eb5f9808-e7e9-47fe-9c54-2cb701347004',\n",
       " '7d19935e-c6f5-49b9-a2e1-bce350668ed6',\n",
       " '367b91c5-f6a1-4662-8b96-14f1cf6a03c4',\n",
       " '2f792f4b-ca97-407e-bcac-c47fba052064',\n",
       " '2a33189b-73d6-4855-80f0-cfb9c4e06bed',\n",
       " 'bf90527a-3945-4e4d-9d1f-e785adbda20b',\n",
       " '48781205-f12f-4f9b-8999-067805b3f783',\n",
       " '1411deea-a42a-42bc-b9a9-4948eb7d3ce7',\n",
       " '5b9192f8-2e13-49c2-8976-4f35e4d13467',\n",
       " '8cf9dce0-21da-471e-84e5-8d5f09773103',\n",
       " 'fad6d761-7005-4c32-9d5f-526ffc1349b3',\n",
       " 'a97e3b7a-3ce6-4678-b4a4-0f8d4beea6f2',\n",
       " '69813981-de98-4411-acf2-22189c64030a',\n",
       " '220dae39-af5a-4e6e-8069-dd06fefc01e0',\n",
       " '39cf7462-2e1e-4300-9559-d4625ccb5fab',\n",
       " '7bb87265-ed92-406e-ba74-007081ba51a4',\n",
       " 'bef4e50b-c618-4da9-ad61-91844512b945',\n",
       " '9c3fbdea-b7d3-461b-a50a-cab4d4577f3c',\n",
       " '2417b549-b864-4a75-980f-fcd2f95c2867',\n",
       " '41242c2b-c502-4313-b8de-553ffd6ee613',\n",
       " 'b292c524-394a-4702-8d7a-1be4896a975b',\n",
       " '9724a4e1-5469-4baf-a38f-c957ca4f01a0',\n",
       " 'd4839a9d-cf28-4182-8f3b-4a78ced67769',\n",
       " 'cf6ffcca-0ef3-4a75-8c72-8cdef610e221',\n",
       " 'cd0ff439-7f65-4202-be39-d4f1c3dc7f68',\n",
       " '037efea2-cae2-4920-a90c-f9fba0009fa5',\n",
       " 'f1005742-9dc4-4bf2-b812-1b0cd11aef03',\n",
       " '48c862b2-441c-481c-950e-79c1e54fa0b5',\n",
       " 'e22e45d0-e855-49d5-8f5d-f089719bf588',\n",
       " 'a632a848-6dc5-4fe4-b432-fddabba8de60',\n",
       " 'ef245f67-3d34-4ae4-b676-f664c269dd9d',\n",
       " 'e9f68560-8f6c-4de6-8ae1-227e0e930baa',\n",
       " 'a70fdb3f-2ecd-429e-a6ba-d3a64ac8a1c5',\n",
       " '7b0246c1-2511-499b-9a1c-d5ab08e08c38',\n",
       " 'c5e7238d-dfd1-4a64-9d81-335593f924f2',\n",
       " 'a788b368-bec3-46cb-b04c-f0a6e4690915',\n",
       " '8838e0ae-9a11-4c23-a6b9-3a7473cfb4d6',\n",
       " '818f8440-f3a7-488d-9267-30b624607ee1',\n",
       " '71ae9ee4-8c28-49ef-8fe6-077f150d9780',\n",
       " 'adde1b91-7dd8-47ec-9f32-fcf5ee1c3b35']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(\n",
    "    documents=split_docs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # retrieve documents Agent\n",
    "\n",
    "# def retrieve_docs(state):\n",
    "#     query= state[\"init\"]\n",
    "#     lecture_docs = vectorstore.similarity_search(query, k=5, namespace=\"lecture\")\n",
    "#     qa_docs = vectorstore.similarity_search(query, k=3, namespace=\"userqa\")\n",
    "#     all_docs = lecture_docs + qa_docs\n",
    "#     return {\"docs\": all_docs, \"query\": query}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_prompt(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qa_docs_with_fallback(query, k):\n",
    "    try:\n",
    "        docs = vector_store.similarity_search(query, k=k, namespace=\"userqna\")\n",
    "        if docs:\n",
    "            return docs\n",
    "        else:\n",
    "            # Fallback: If no documents found, return a default message\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(\"에러 발생:\", e)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate script Agent\n",
    "\n",
    "def generate_script(state):\n",
    "\n",
    "    # 1. Retrieve documents\n",
    "    query= state[\"init\"]\n",
    "    lecture_docs = vector_store.similarity_search(query, k=5, namespace=\"lecture\")\n",
    "    qa_docs = get_qa_docs_with_fallback(query, k=1)\n",
    "    all_docs = lecture_docs + qa_docs\n",
    "\n",
    "    # 2. Create user and system prompts\n",
    "    content = \"\\n\\n\".join([doc.page_content for doc in all_docs])\n",
    "    user_prompt = f\"다음은 참고할 문서 내용입니다:\\n\\n{content}\"\n",
    "    system_prompt = read_prompt(\"summary_prompt.txt\")\n",
    "\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.7\n",
    "    )\n",
    "    return {\"script\": response.choices[0].message.content, \"docs\": all_docs, \"query\": query}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_tts(state):\n",
    "    script = state[\"script\"]\n",
    "    audio_response = client.audio.speech.create(\n",
    "        model=\"tts-1\",\n",
    "        voice=\"nova\",\n",
    "        input=script\n",
    "    )\n",
    "    file_name = \"podcast_script.mp3\"\n",
    "    with open(file_name, \"wb\") as f:\n",
    "        f.write(audio_response.content)\n",
    "    return {\"script\": script, \"audio_file\": file_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TBU : User Query (Added to Vector Store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_from_vectorstore(state):\n",
    "    user_query = state[\"user_query\"]\n",
    "    docs = vector_store.similarity_search(user_query, k=5, namespace=\"lecturedata\")\n",
    "    content = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "    prompt = f\"다음 문서를 참고하여 사용자의 질문에 답해주세요:\\n\\n{content}\\n\\n질문: {user_query}\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.5\n",
    "    )\n",
    "    answer = response.choices[0].message.content\n",
    "\n",
    "    # vectorstore에 질문/답변 저장\n",
    "    now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    qa_doc = Document(\n",
    "        page_content=f\"Q: {user_query}\\nA: {answer}\",\n",
    "        metadata={\"source\": \"userqa\", \"timestamp\": now}\n",
    "    )\n",
    "    vector_store.add_documents([qa_doc], namespace=\"userqna\")\n",
    "    return {\"answer\": answer} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiAgent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import Langfuse\n",
    "from langfuse.callback import CallbackHandler\n",
    "\n",
    "langfuse_handler = CallbackHandler(\n",
    "  secret_key=LANGFUSE_SECRET_KEY,\n",
    "  public_key=LANGFUSE_PUBLIC_KEY,\n",
    "  host=\"https://us.cloud.langfuse.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LangGraph State definition\n",
    "\n",
    "from typing import TypedDict, Optional\n",
    "\n",
    "\n",
    "class ChatState(TypedDict):\n",
    "    init: str\n",
    "    docs: Optional[list[Document]]\n",
    "    script: Optional[str]\n",
    "    audio_file: Optional[str]\n",
    "    user_query: Optional[str]\n",
    "    answer: Optional[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent node definition\n",
    "\n",
    "\n",
    "def script_generation(state: ChatState) -> ChatState:\n",
    "    generated_script = generate_script(state)\n",
    "    return {**state, \"script\": generated_script[\"script\"]}\n",
    "\n",
    "def tts_generation(state: ChatState) -> ChatState:\n",
    "    tts_result = synthesize_tts(state)\n",
    "    return {**state, \"audio_file\": tts_result[\"audio_file\"]}\n",
    "\n",
    "def save_to_vector_store(state: ChatState) -> None:\n",
    "    user_qna_data = answer_from_vectorstore(state)\n",
    "    return {**state, \"answer\": user_qna_data[\"answer\"]}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#workflow connection\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "workflow = StateGraph(ChatState)\n",
    "\n",
    "workflow.add_node(\"Script Generation\", RunnableLambda(script_generation))\n",
    "workflow.add_node(\"TTS Generation\", RunnableLambda(tts_generation))\n",
    "workflow.add_node(\"User QnA\", RunnableLambda(save_to_vector_store))\n",
    "\n",
    "workflow.set_entry_point(\"Script Generation\")\n",
    "workflow.add_edge(\"Script Generation\", \"TTS Generation\")\n",
    "workflow.add_edge(\"TTS Generation\", \"User QnA\")\n",
    "workflow.set_finish_point(\"User QnA\")\n",
    "\n",
    "graph = workflow.compile().with_config({\"callbacks\": [langfuse_handler]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'init': '강의 내용을 요약한 팟캐스트를 만들어줘', 'docs': None, 'script': '[인트로 음악]\\n\\n안녕하세요, 여러분! \\'테크 토크\\'에 오신 걸 환영합니다! 저는 여러분의 팟캐스트 호스트, 카이로스입니다. 오늘은 조금은 기술적인 이야기를 해보려고 해요. 바로 소프트웨어 개발에서 자주 언급되는 함수, `ip_finish_output`과 `ip_finish_output2`에 대한 이야기입니다.\\n\\n자, 여러분. 혹시 프로그래밍을 하면서 비슷한 이름의 함수들을 보고 \"이게 뭐가 다른 거지?\" 하고 헷갈렸던 적 있지 않나요? 오늘 다룰 주제가 바로 그런 케이스입니다. `ip_finish_output`과 `ip_finish_output2`, 이름만 보면 둘 다 무언가를 \\'끝내는\\' 역할을 하는 것 같죠? 하지만 구체적으로 어떻게 다르고, 왜 이렇게 이름이 비슷한 두 함수가 존재하는지 궁금하지 않으세요?\\n\\n아쉽게도, 제가 직접 그 차이점을 설명하는 문서를 가지고 있진 않아요. 그래서 오늘은 여러분이 이런 상황에 마주쳤을 때, 어떻게 접근하면 좋을지에 대해 이야기해보려고 합니다. \\n\\n먼저, 함수의 차이를 이해하려면 그 함수들이 정의된 문서나 소스 코드를 직접 살펴보는 게 가장 중요해요. 각 함수의 목적이 무엇인지, 어떤 매개변수를 받는지, 반환값은 무엇인지, 그리고 내부적으로 어떤 로직으로 구현되어 있는지를 살펴보는 것이죠.\\n\\n예를 들어, `ip_finish_output`과 `ip_finish_output2`라는 함수가 있다고 칩시다. 이 두 함수는 아마도 비슷한 기능을 수행하면서 약간의 차이점을 가질 가능성이 큽니다. 이런 경우, 함수의 이름만 보고 판단하기보다는, 문서화된 설명이나 주석을 참고하여 두 함수가 정확히 어떤 기능을 수행하는지 비교해보는 것이 중요해요.\\n\\n또한, 이 함수들이 사용되는 실제 사례를 살펴보는 것도 좋은 방법입니다. 소스 코드에서 이 함수들이 어떻게 사용되는지를 보면, 일반적으로 예상되는 사용 패턴이나 컨텍스트를 이해하는 데 큰 도움이 됩니다.\\n\\n마지막으로, 커뮤니티의 도움을 받는 것도 좋습니다. 오픈소스 프로젝트라면 GitHub 같은 플랫폼에서 관련 이슈나 토론을 찾아보고, 다른 개발자들이 이 함수들을 어떻게 다루고 있는지 참고할 수 있을 거예요.\\n\\n오늘은 이렇게, 직접 문서가 없을 때 두 함수의 차이를 이해하는 방법에 대해 이야기해봤습니다. 여러분이 다음에 비슷한 상황에 처했을 때 오늘의 팁이 도움이 되었으면 좋겠어요!\\n\\n그럼 오늘의 \\'테크 토크\\'는 여기서 마치도록 하겠습니다. 여러분의 모든 코딩 여정에 도움이 되는 팟캐스트가 되길 바라며, 다음 시간에 또 만나요!\\n\\n[클로징 음악]', 'audio_file': 'podcast_script.mp3', 'user_query': 'ip_finish_output 과 ip_finish_output2의 차이점은?', 'answer': \"ip_finish_output과 ip_finish_output2의 차이점은 주로 패킷의 분할 여부에 따라 결정됩니다.\\n\\n1. **ip_finish_output**:\\n   - 이 함수는 패킷의 길이가 목적지의 MTU(Maximum Transmission Unit)를 초과하는지를 확인합니다.\\n   - 만약 패킷이 MTU를 초과하면, 패킷을 여러 조각으로 나누는 'fragmentation' 과정이 필요합니다.\\n   - 이 경우, ip_fragment() 함수를 호출하여 패킷을 분할하고, 각 분할된 조각은 다시 ip_finish_output()과 ip_finish_output2()를 통해 처리됩니다.\\n\\n2. **ip_finish_output2**:\\n   - 이 함수는 패킷 분할이 필요 없는 경우에 호출됩니다.\\n   - 즉, 패킷의 길이가 MTU 이하일 때 직접적으로 이 함수가 호출되어 패킷을 전송합니다.\\n\\n따라서 ip_finish_output은 패킷의 길이를 검사하고 필요시 분할하는 역할을 주로 하며, ip_finish_output2는 분할이 필요 없는 패킷을 처리하는 역할을 합니다.\"}\n"
     ]
    }
   ],
   "source": [
    "state = {\n",
    "    \"init\": \"강의 내용을 요약한 팟캐스트를 만들어줘\",\n",
    "    \"user_query\" : \"ip_finish_output 과 ip_finish_output2의 차이점은?\",\n",
    "    \"docs\": None,\n",
    "    \"script\": None,\n",
    "    \"audio_file\": None,\n",
    "    \"answer\": None\n",
    "}\n",
    "\n",
    "\n",
    "result = graph.invoke(state)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "config:\n",
      "  flowchart:\n",
      "    curve: linear\n",
      "---\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\tScript_Generation(Script Generation)\n",
      "\tTTS_Generation(TTS Generation)\n",
      "\tUser_QnA(User QnA)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\tScript_Generation --> TTS_Generation;\n",
      "\tTTS_Generation --> User_QnA;\n",
      "\t__start__ --> Script_Generation;\n",
      "\tUser_QnA --> __end__;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(graph.get_graph().draw_mermaid())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
