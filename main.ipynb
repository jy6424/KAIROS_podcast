{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yjw64\\projects\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langfuse import Langfuse\n",
    "from langchain_community.document_loaders import PyPDFLoader  \n",
    "import os\n",
    "import re\n",
    "from pinecone import Pinecone\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import StateGraph\n",
    "from langfuse import Langfuse\n",
    "from langfuse.callback import CallbackHandler\n",
    "from langchain.schema import Document\n",
    "from datetime import datetime\n",
    "from datetime import datetime\n",
    "\n",
    "# from langfuse.client import CreateTracer, Creategeneration, CreateSpan\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "LANGFUSE_SECRET_KEY = os.getenv(\"LANGFUSE_SECRET_KEY\")\n",
    "LANGFUSE_PUBLIC_KEY = os.getenv(\"LANGFUSE_PUBLIC_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "langfuse = Langfuse( \n",
    "    secret_key=LANGFUSE_SECRET_KEY,\n",
    "    public_key=LANGFUSE_PUBLIC_KEY,\n",
    "    host=\"https://us.cloud.langfuse.com\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF Read Agent + RAG using Pinecone\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF Read Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ OpenAI API 키 설정\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# ✅ PDF → 이미지 변환\n",
    "def convert_pdf_to_images(pdf_path, dpi=150, poppler_path=None):\n",
    "    return convert_from_path(pdf_path, dpi=dpi, poppler_path=poppler_path)\n",
    "\n",
    "# ✅ 이미지 → base64 변환\n",
    "def encode_image_to_base64(image: Image.Image) -> str:\n",
    "    buffered = BytesIO()\n",
    "    image.save(buffered, format=\"PNG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode()\n",
    "\n",
    "# ✅ Vision API 호출\n",
    "def summarize_image(image: Image.Image, prompt=\"이 이미지를 요약해줘\"):\n",
    "    base64_image = encode_image_to_base64(image)\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4-vision-preview\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\n",
    "                    \"url\": f\"data:image/png;base64,{base64_image}\" }}\n",
    "            ]}\n",
    "        ],\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def ask_gpt4_vision(base64_image: str, prompt: str) -> str:\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image}\"}}\n",
    "            ]\n",
    "        }],\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page 1 of [Lecture] 12. IP in Linux.pdf\n",
      "Page 1 summary done\n",
      "\n",
      "Processing page 2 of [Lecture] 12. IP in Linux.pdf\n",
      "Page 2 summary done\n",
      "\n",
      "Processing page 3 of [Lecture] 12. IP in Linux.pdf\n",
      "Page 3 summary done\n",
      "\n",
      "Processing page 4 of [Lecture] 12. IP in Linux.pdf\n",
      "Page 4 summary done\n",
      "\n",
      "Processing page 5 of [Lecture] 12. IP in Linux.pdf\n",
      "Page 5 summary done\n",
      "\n",
      "Processing page 6 of [Lecture] 12. IP in Linux.pdf\n",
      "Page 6 summary done\n",
      "\n",
      "Processing page 7 of [Lecture] 12. IP in Linux.pdf\n",
      "Page 7 summary done\n",
      "\n",
      "Processing page 8 of [Lecture] 12. IP in Linux.pdf\n",
      "Page 8 summary done\n",
      "\n",
      "Processing page 9 of [Lecture] 12. IP in Linux.pdf\n",
      "Page 9 summary done\n",
      "\n",
      "Processing page 10 of [Lecture] 12. IP in Linux.pdf\n",
      "Page 10 summary done\n",
      "\n",
      "Processing page 11 of [Lecture] 12. IP in Linux.pdf\n",
      "Page 11 summary done\n",
      "\n",
      "Processing page 12 of [Lecture] 12. IP in Linux.pdf\n",
      "Page 12 summary done\n",
      "\n",
      "Processing page 13 of [Lecture] 12. IP in Linux.pdf\n",
      "Page 13 summary done\n",
      "\n",
      "Processing page 14 of [Lecture] 12. IP in Linux.pdf\n",
      "Page 14 summary done\n",
      "\n",
      "Processing page 15 of [Lecture] 12. IP in Linux.pdf\n",
      "Page 15 summary done\n",
      "\n",
      "Processing page 16 of [Lecture] 12. IP in Linux.pdf\n",
      "Page 16 summary done\n",
      "\n",
      "Processing page 17 of [Lecture] 12. IP in Linux.pdf\n",
      "Page 17 summary done\n",
      "\n",
      "Processing page 18 of [Lecture] 12. IP in Linux.pdf\n",
      "Page 18 summary done\n",
      "\n",
      "Processing page 19 of [Lecture] 12. IP in Linux.pdf\n",
      "Page 19 summary done\n",
      "\n",
      "Processing page 20 of [Lecture] 12. IP in Linux.pdf\n",
      "Page 20 summary done\n",
      "\n",
      "Processing page 21 of [Lecture] 12. IP in Linux.pdf\n",
      "Page 21 summary done\n",
      "\n",
      "Processing page 22 of [Lecture] 12. IP in Linux.pdf\n",
      "Page 22 summary done\n",
      "\n",
      "Processing page 23 of [Lecture] 12. IP in Linux.pdf\n",
      "Page 23 summary done\n",
      "\n",
      "Processing page 24 of [Lecture] 12. IP in Linux.pdf\n",
      "Page 24 summary done\n",
      "\n",
      "Processing page 25 of [Lecture] 12. IP in Linux.pdf\n",
      "Page 25 summary done\n",
      "\n",
      "Processing page 26 of [Lecture] 12. IP in Linux.pdf\n",
      "Page 26 summary done\n",
      "\n",
      "Processing page 27 of [Lecture] 12. IP in Linux.pdf\n",
      "Page 27 summary done\n",
      "\n",
      "Processing page 28 of [Lecture] 12. IP in Linux.pdf\n",
      "Page 28 summary done\n",
      "\n",
      "Processing page 29 of [Lecture] 12. IP in Linux.pdf\n",
      "Page 29 summary done\n",
      "\n",
      "Processing page 30 of [Lecture] 12. IP in Linux.pdf\n",
      "Page 30 summary done\n",
      "\n",
      "Processing page 31 of [Lecture] 12. IP in Linux.pdf\n",
      "Page 31 summary done\n",
      "\n",
      "Processing page 32 of [Lecture] 12. IP in Linux.pdf\n",
      "Page 32 summary done\n",
      "\n",
      "Processing page 33 of [Lecture] 12. IP in Linux.pdf\n",
      "Page 33 summary done\n",
      "\n",
      "Processing page 34 of [Lecture] 12. IP in Linux.pdf\n",
      "Page 34 summary done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pdf_paths = [r\"C:\\Users\\yjw64\\projects\\github\\kairos\\KAIROS_Podcast\\example_files\\[Lecture] 12. IP in Linux.pdf\" ] # 여기에 PDF 경로 입력\n",
    "documents = []\n",
    "date = datetime.today().strftime(\"%Y-%m-%d\") \n",
    "\n",
    "# PDF 파일에서 각 페이지를 이미지로 변환하고 요약 생성\n",
    "for path in pdf_paths:\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"파일 없음: {path}\")\n",
    "        continue\n",
    "    lecture_name = os.path.basename(path)\n",
    "    images = convert_pdf_to_images(path, dpi=150, poppler_path=r\"C:\\Users\\yjw64\\projects\\github\\kairos\\KAIROS_Podcast\\poppler-24.08.0\\Library\\bin\")\n",
    "    for i, image in enumerate(images):\n",
    "        print(f\"Processing page {i + 1} of {lecture_name}\")\n",
    "        base64_image = encode_image_to_base64(image)\n",
    "        summary = ask_gpt4_vision(base64_image, prompt= \"이 페이지의 주요 내용을 요약해줘\")\n",
    "        documents.append(Document(\n",
    "            page_content=summary,\n",
    "            metadata={\n",
    "                \"lecture_name\": lecture_name,\n",
    "                \"upload_date\": date,\n",
    "                \"page\": i + 1\n",
    "            }\n",
    "        ))\n",
    "        print(f\"Page {i + 1} summary done\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'lecture_name': '[Lecture] 12. IP in Linux.pdf', 'upload_date': '2025-05-27', 'page': 2}, page_content='이 페이지는 IP(인터넷 프로토콜)에 대한 내용을 다룹니다. 주요 내용은 다음과 같습니다:\\n\\n1. **IP 개요**\\n   - IP 리뷰\\n   - IP의 데이터 구조\\n\\n2. **IP 주요 기능: 라우팅**\\n   - IP 라우팅 절차\\n   - IP 라우팅을 위한 데이터 구조\\n\\n3. **IP의 실제 구현**\\n   - IP 구현 아키텍처\\n   - IP 계층으로의 패킷 소스\\n   - IP 출력\\n   - IP 입력\\n   - 패킷 전달\\n\\n이 내용은 시스템 프로그래밍 수업의 일환으로 제시되었습니다.')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to vectorstore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yjw64\\AppData\\Local\\Temp\\ipykernel_16196\\1909058095.py:2: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "# OpenAIEmbeddings 인스턴스 생성\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    model=\"text-embedding-3-small\"\n",
    ")\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index = pc.Index(\"kairos-podcast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'userqna': {'vector_count': 6}},\n",
      " 'total_vector_count': 6,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "#check connection\n",
    "print(index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#저장할 vector store 불러오기\n",
    "vector_store = PineconeVectorStore(\n",
    "    index=index, \n",
    "    embedding=embeddings,\n",
    "    namespace=\"lecturedata\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "split_docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d5b6ee96-90d2-4cad-b115-37c5761203d6',\n",
       " 'f7b08ca9-005a-4def-8375-352dbbeb83d0',\n",
       " 'f8a131f8-00b6-472b-9366-6ef9bfc49c48',\n",
       " 'cf5f4026-49ef-4f0a-ba00-ec6ac2506724',\n",
       " '59826e76-a347-41c8-bbad-fc8fb27607ce',\n",
       " '9302a03c-2cc6-4c9a-ac95-f71d6d37b63f',\n",
       " '6208053d-b1ad-4fb7-8fca-a6758ef39fa5',\n",
       " 'c3413211-8723-496f-a2e3-711d9b8332d1',\n",
       " '4e102bd2-90fd-44ab-a6d6-65f5438e346f',\n",
       " '2c2e9c85-2c6c-4570-b925-fc325e03f0a5',\n",
       " '46eb1f1f-791f-4716-b543-e0df8546272d',\n",
       " '77083851-07b4-4ea8-8a23-9514eb95a17d',\n",
       " '9c3f9a99-31ab-4722-931a-424ad0cefcb7',\n",
       " '13fcaa2e-776a-4c98-b556-43104fec14db',\n",
       " '64516afe-9af0-4fee-a041-cd30c24317b1',\n",
       " 'fb98f229-4f27-429a-a019-218c9a1251c9',\n",
       " '6ea450e4-02ac-4259-92ec-d2ab5d0e8bf8',\n",
       " '51444c37-a113-4d8b-9567-88eb95e3deda',\n",
       " '2c83a6f9-5157-44c7-a46a-659263d321bc',\n",
       " 'c2a700e0-41bf-4db0-9060-9e70cb3e1508',\n",
       " 'cd3151bb-6f1e-4b6d-847b-cae291f08329',\n",
       " 'bb5bb8c8-c499-433a-9e59-5aed5a7ec92b',\n",
       " '04d7c92a-8180-4023-ae3b-b6b5d796521e',\n",
       " '592d7cba-b4b8-4c39-a27d-febbd44b8fac',\n",
       " 'cd7f377c-7668-4389-8461-95ecbee7a831',\n",
       " 'fd7eb4eb-95b5-467e-82f1-701334cec3e6',\n",
       " '416fdac2-f25c-4cd9-a0a9-8d797dc2ea0f',\n",
       " 'bbe5f3a2-5143-48fc-9856-35df16cd9b52',\n",
       " '7af91448-6e0f-42a9-b29d-3ef1fc4b686c',\n",
       " 'f4ccf6d5-da89-468c-a8d6-995401318dce',\n",
       " 'b04793bd-15c0-49ab-889a-a0ddd2ca6643',\n",
       " 'c1320a69-9a2a-499b-b0b3-a635031a5eea',\n",
       " '8c994260-7aad-4c48-bab0-85c949671426',\n",
       " '8d603a06-9696-4395-b478-8764442881ff',\n",
       " '620a200e-c785-4e24-bcd1-59fea6a214c3',\n",
       " 'aa8b1f5e-bfcf-40ea-b996-6d84a3a86803',\n",
       " '671363eb-1a1b-4b9e-85cb-e799f13e2f01',\n",
       " '7dfd1afe-4f30-47d3-beab-d389af904bbf',\n",
       " '0ba805b6-6816-4d22-8ac5-da46e69431af',\n",
       " '460a5e84-26e2-476e-839d-c6a906e15bfc']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(\n",
    "    documents=split_docs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # retrieve documents Agent\n",
    "\n",
    "# def retrieve_docs(state):\n",
    "#     query= state[\"init\"]\n",
    "#     lecture_docs = vectorstore.similarity_search(query, k=5, namespace=\"lecture\")\n",
    "#     qa_docs = vectorstore.similarity_search(query, k=3, namespace=\"userqa\")\n",
    "#     all_docs = lecture_docs + qa_docs\n",
    "#     return {\"docs\": all_docs, \"query\": query}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Agent (Generate Script)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_prompt(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read().strip()\n",
    "\n",
    "#if not related QA found, return empty list\n",
    "def get_qa_docs_with_fallback(query, k):\n",
    "    try:\n",
    "        docs = vector_store.similarity_search(query, k=k, namespace=\"userqna\")\n",
    "        if docs:\n",
    "            return docs\n",
    "        else:\n",
    "            # Fallback: If no documents found, return a default message\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(\"에러 발생:\", e)\n",
    "        return []\n",
    "    \n",
    "\n",
    "#generate script Agent\n",
    "\n",
    "def generate_script(state):\n",
    "\n",
    "    # 1. Retrieve documents\n",
    "    query= state[\"init\"]\n",
    "    lecture_docs = vector_store.similarity_search(query, k=5, namespace=\"lecture\")\n",
    "    qa_docs = get_qa_docs_with_fallback(query, k=1)\n",
    "    all_docs = lecture_docs + qa_docs\n",
    "\n",
    "    # 2. Create user and system prompts\n",
    "    content = \"\\n\\n\".join([doc.page_content for doc in all_docs])\n",
    "    user_prompt = f\"다음은 참고할 문서 내용입니다:\\n\\n{content}\"\n",
    "    system_prompt = read_prompt(\"summary_prompt.txt\")\n",
    "\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.7\n",
    "    )\n",
    "    return {\"script\": response.choices[0].message.content, \"docs\": all_docs, \"query\": query}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User QnA Agent (Added to Vector Store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_from_vectorstore(state):\n",
    "    user_query = state[\"user_query\"]\n",
    "    docs = vector_store.similarity_search(user_query, k=5, namespace=\"lecturedata\")\n",
    "    content = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "    prompt = f\"다음 문서를 참고하여 사용자의 질문에 답해주세요:\\n\\n{content}\\n\\n질문: {user_query}\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.5\n",
    "    )\n",
    "    answer = response.choices[0].message.content\n",
    "\n",
    "    # vectorstore에 질문/답변 저장\n",
    "    now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    qa_doc = Document(\n",
    "        page_content=f\"Q: {user_query}\\nA: {answer}\",\n",
    "        metadata={\"source\": \"userqa\", \"timestamp\": now}\n",
    "    )\n",
    "    vector_store.add_documents([qa_doc], namespace=\"userqna\")\n",
    "    return {\"answer\": answer} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TTS Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate TTS Agent\n",
    "\n",
    "def synthesize_tts(state):\n",
    "    script = state[\"script\"]\n",
    "    audio_response = client.audio.speech.create(\n",
    "        model=\"tts-1\",\n",
    "        voice=\"nova\",\n",
    "        input=script\n",
    "    )\n",
    "    file_name = \"podcast_script.mp3\"\n",
    "    with open(file_name, \"wb\") as f:\n",
    "        f.write(audio_response.content)\n",
    "    return {\"script\": script, \"audio_file\": file_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiAgent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import Langfuse\n",
    "from langfuse.callback import CallbackHandler\n",
    "\n",
    "langfuse_handler = CallbackHandler(\n",
    "  secret_key=LANGFUSE_SECRET_KEY,\n",
    "  public_key=LANGFUSE_PUBLIC_KEY,\n",
    "  host=\"https://us.cloud.langfuse.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LangGraph State definition\n",
    "from typing import TypedDict, Optional\n",
    "\n",
    "\n",
    "class ChatState(TypedDict):\n",
    "    init: str\n",
    "    docs: Optional[list[Document]]\n",
    "    script: Optional[str]\n",
    "    audio_file: Optional[str]\n",
    "    user_query: Optional[str]\n",
    "    answer: Optional[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent node definition\n",
    "\n",
    "def script_generation(state: ChatState) -> ChatState:\n",
    "    generated_script = generate_script(state)\n",
    "    return {**state, \"script\": generated_script[\"script\"]}\n",
    "\n",
    "def tts_generation(state: ChatState) -> ChatState:\n",
    "    tts_result = synthesize_tts(state)\n",
    "    return {**state, \"audio_file\": tts_result[\"audio_file\"]}\n",
    "\n",
    "def save_to_vector_store(state: ChatState) -> None:\n",
    "    user_qna_data = answer_from_vectorstore(state)\n",
    "    return {**state, \"answer\": user_qna_data[\"answer\"]}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#workflow connection\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "workflow = StateGraph(ChatState)\n",
    "\n",
    "workflow.add_node(\"Script Generation\", RunnableLambda(script_generation))\n",
    "workflow.add_node(\"TTS Generation\", RunnableLambda(tts_generation))\n",
    "workflow.add_node(\"User QnA\", RunnableLambda(save_to_vector_store))\n",
    "\n",
    "workflow.set_entry_point(\"Script Generation\")\n",
    "workflow.add_edge(\"Script Generation\", \"TTS Generation\")\n",
    "workflow.add_edge(\"TTS Generation\", \"User QnA\")\n",
    "workflow.set_finish_point(\"User QnA\")\n",
    "\n",
    "graph = workflow.compile().with_config({\"callbacks\": [langfuse_handler]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'init': '강의 내용을 요약한 팟캐스트를 만들어줘', 'docs': None, 'script': '[인트로 음악]\\n\\n안녕하세요, 여러분! \\'테크 토크\\'에 오신 걸 환영합니다! 저는 여러분의 팟캐스트 호스트, 카이로스입니다. 오늘은 조금은 기술적인 이야기를 해보려고 해요. 바로 소프트웨어 개발에서 자주 언급되는 함수, `ip_finish_output`과 `ip_finish_output2`에 대한 이야기입니다.\\n\\n자, 여러분. 혹시 프로그래밍을 하면서 비슷한 이름의 함수들을 보고 \"이게 뭐가 다른 거지?\" 하고 헷갈렸던 적 있지 않나요? 오늘 다룰 주제가 바로 그런 케이스입니다. `ip_finish_output`과 `ip_finish_output2`, 이름만 보면 둘 다 무언가를 \\'끝내는\\' 역할을 하는 것 같죠? 하지만 구체적으로 어떻게 다르고, 왜 이렇게 이름이 비슷한 두 함수가 존재하는지 궁금하지 않으세요?\\n\\n아쉽게도, 제가 직접 그 차이점을 설명하는 문서를 가지고 있진 않아요. 그래서 오늘은 여러분이 이런 상황에 마주쳤을 때, 어떻게 접근하면 좋을지에 대해 이야기해보려고 합니다. \\n\\n먼저, 함수의 차이를 이해하려면 그 함수들이 정의된 문서나 소스 코드를 직접 살펴보는 게 가장 중요해요. 각 함수의 목적이 무엇인지, 어떤 매개변수를 받는지, 반환값은 무엇인지, 그리고 내부적으로 어떤 로직으로 구현되어 있는지를 살펴보는 것이죠.\\n\\n예를 들어, `ip_finish_output`과 `ip_finish_output2`라는 함수가 있다고 칩시다. 이 두 함수는 아마도 비슷한 기능을 수행하면서 약간의 차이점을 가질 가능성이 큽니다. 이런 경우, 함수의 이름만 보고 판단하기보다는, 문서화된 설명이나 주석을 참고하여 두 함수가 정확히 어떤 기능을 수행하는지 비교해보는 것이 중요해요.\\n\\n또한, 이 함수들이 사용되는 실제 사례를 살펴보는 것도 좋은 방법입니다. 소스 코드에서 이 함수들이 어떻게 사용되는지를 보면, 일반적으로 예상되는 사용 패턴이나 컨텍스트를 이해하는 데 큰 도움이 됩니다.\\n\\n마지막으로, 커뮤니티의 도움을 받는 것도 좋습니다. 오픈소스 프로젝트라면 GitHub 같은 플랫폼에서 관련 이슈나 토론을 찾아보고, 다른 개발자들이 이 함수들을 어떻게 다루고 있는지 참고할 수 있을 거예요.\\n\\n오늘은 이렇게, 직접 문서가 없을 때 두 함수의 차이를 이해하는 방법에 대해 이야기해봤습니다. 여러분이 다음에 비슷한 상황에 처했을 때 오늘의 팁이 도움이 되었으면 좋겠어요!\\n\\n그럼 오늘의 \\'테크 토크\\'는 여기서 마치도록 하겠습니다. 여러분의 모든 코딩 여정에 도움이 되는 팟캐스트가 되길 바라며, 다음 시간에 또 만나요!\\n\\n[클로징 음악]', 'audio_file': 'podcast_script.mp3', 'user_query': 'ip_finish_output 과 ip_finish_output2의 차이점은?', 'answer': \"ip_finish_output과 ip_finish_output2의 차이점은 주로 패킷의 분할 여부에 따라 결정됩니다.\\n\\n1. **ip_finish_output**:\\n   - 이 함수는 패킷의 길이가 목적지의 MTU(Maximum Transmission Unit)를 초과하는지를 확인합니다.\\n   - 만약 패킷이 MTU를 초과하면, 패킷을 여러 조각으로 나누는 'fragmentation' 과정이 필요합니다.\\n   - 이 경우, ip_fragment() 함수를 호출하여 패킷을 분할하고, 각 분할된 조각은 다시 ip_finish_output()과 ip_finish_output2()를 통해 처리됩니다.\\n\\n2. **ip_finish_output2**:\\n   - 이 함수는 패킷 분할이 필요 없는 경우에 호출됩니다.\\n   - 즉, 패킷의 길이가 MTU 이하일 때 직접적으로 이 함수가 호출되어 패킷을 전송합니다.\\n\\n따라서 ip_finish_output은 패킷의 길이를 검사하고 필요시 분할하는 역할을 주로 하며, ip_finish_output2는 분할이 필요 없는 패킷을 처리하는 역할을 합니다.\"}\n"
     ]
    }
   ],
   "source": [
    "state = {\n",
    "    \"init\": \"강의 내용을 요약한 팟캐스트를 만들어줘\",\n",
    "    \"user_query\" : \"ip_finish_output 과 ip_finish_output2의 차이점은?\",\n",
    "    \"docs\": None,\n",
    "    \"script\": None,\n",
    "    \"audio_file\": None,\n",
    "    \"answer\": None\n",
    "}\n",
    "\n",
    "\n",
    "result = graph.invoke(state)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "config:\n",
      "  flowchart:\n",
      "    curve: linear\n",
      "---\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\tScript_Generation(Script Generation)\n",
      "\tTTS_Generation(TTS Generation)\n",
      "\tUser_QnA(User QnA)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\tScript_Generation --> TTS_Generation;\n",
      "\tTTS_Generation --> User_QnA;\n",
      "\t__start__ --> Script_Generation;\n",
      "\tUser_QnA --> __end__;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(graph.get_graph().draw_mermaid())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
